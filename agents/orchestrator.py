"""
Agente Orquestrador Principal - ResponsÃ¡vel por analisar mensagens do usuÃ¡rio,
identificar intenÃ§Ãµes e coordenar com outros agentes especializados.
"""

import os
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

from models.schemas import (
    WebhookPayload, 
    OrchestratorResponse, 
    AgentIntent, 
    IntentAnalysis,
    ConversationMessage,
    MessageRole
)

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntentAnalysisOutput(BaseModel):
    """Modelo para saÃ­da da anÃ¡lise de intenÃ§Ã£o."""
    intent: str = Field(description="Tipo de intenÃ§Ã£o identificada")
    confidence: float = Field(description="ConfianÃ§a na identificaÃ§Ã£o (0-1)")
    extracted_parameters: Dict[str, Any] = Field(description="ParÃ¢metros extraÃ­dos da mensagem")
    reasoning: str = Field(description="ExplicaÃ§Ã£o do raciocÃ­nio")


class OrchestratorAgent:
    """
    Agente Orquestrador Principal que coordena todo o fluxo de processamento.
    """
    
    def __init__(self):
        """Inicializa o agente orquestrador."""
        self.llm = ChatOpenAI(
            model="gpt-4.1-mini",
            temperature=0.1,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Parser para anÃ¡lise de intenÃ§Ã£o
        self.intent_parser = JsonOutputParser(pydantic_object=IntentAnalysisOutput)
        
        # Template para anÃ¡lise de intenÃ§Ã£o
        self.intent_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self._get_intent_system_prompt()),
            MessagesPlaceholder(variable_name="conversation_history"),
            HumanMessage(content="Mensagem atual: {user_message}")
        ])
        
        # Template para geraÃ§Ã£o de resposta final
        self.response_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self._get_response_system_prompt()),
            MessagesPlaceholder(variable_name="conversation_history"),
            HumanMessage(content="""
            Dados da consulta SQL: {sql_data}
            Mensagem original do usuÃ¡rio: {user_message}
            
            Gere uma resposta natural e informativa baseada nos dados retornados.
            """)
        ])
    
    def _get_intent_system_prompt(self) -> str:
        """Retorna o prompt do sistema para anÃ¡lise de intenÃ§Ã£o."""
        return """
        VocÃª Ã© um assistente especializado em analisar intenÃ§Ãµes de usuÃ¡rios em um sistema de chat.
        Sua funÃ§Ã£o Ã© identificar o que o usuÃ¡rio deseja fazer e extrair parÃ¢metros relevantes.
        
        Tipos de intenÃ§Ã£o possÃ­veis:
        - "sql_query": UsuÃ¡rio quer fazer uma consulta ao banco de dados (ex: "quantos usuÃ¡rios temos?", "mostre as vendas do mÃªs")
        - "general_chat": Conversa geral, saudaÃ§Ãµes, perguntas sobre o sistema
        - "help": UsuÃ¡rio precisa de ajuda ou instruÃ§Ãµes
        - "unknown": NÃ£o foi possÃ­vel identificar a intenÃ§Ã£o
        
        Para intenÃ§Ãµes "sql_query", extraia parÃ¢metros como:
        - tabelas mencionadas
        - campos de interesse
        - filtros (datas, categorias, etc.)
        - tipo de agregaÃ§Ã£o (soma, contagem, mÃ©dia, etc.)
        
        Responda SEMPRE em formato JSON vÃ¡lido seguindo o schema especificado.
        Seja preciso na identificaÃ§Ã£o da intenÃ§Ã£o e confiante na sua anÃ¡lise.
        """
    
    def _get_response_system_prompt(self) -> str:
        """Retorna o prompt do sistema para geraÃ§Ã£o de resposta."""
        return """
        VocÃª Ã© um assistente que converte dados estruturados em respostas naturais e informativas.
        
        Diretrizes:
        1. Seja claro e objetivo na resposta
        2. Use linguagem natural e amigÃ¡vel
        3. Se houver dados numÃ©ricos, apresente-os de forma organizada
        4. Se nÃ£o houver dados, explique o motivo de forma educada
        5. Mantenha o contexto da conversa
        6. Use formataÃ§Ã£o quando apropriado (listas, tabelas simples)
        
        Sempre responda em portuguÃªs brasileiro.
        """
    
    async def analyze_intent(self, payload: WebhookPayload) -> IntentAnalysis:
        """
        Analisa a intenÃ§Ã£o da mensagem do usuÃ¡rio.
        
        Args:
            payload: Dados recebidos do webhook
            
        Returns:
            IntentAnalysis: Resultado da anÃ¡lise de intenÃ§Ã£o
        """
        try:
            # Converter histÃ³rico para formato do LangChain
            messages = self._convert_history_to_messages(payload.conversation_history)
            
            # Executar anÃ¡lise de intenÃ§Ã£o
            chain = self.intent_prompt | self.llm | self.intent_parser
            
            result = await chain.ainvoke({
                "conversation_history": messages,
                "user_message": payload.user_message
            })
            
            # Converter resultado para nosso modelo
            intent_analysis = IntentAnalysis(
                intent=AgentIntent(result["intent"]),
                confidence=result["confidence"],
                extracted_parameters=result["extracted_parameters"],
                reasoning=result["reasoning"]
            )
            
            logger.info(f"Intent analyzed: {intent_analysis.intent} (confidence: {intent_analysis.confidence})")
            return intent_analysis
            
        except Exception as e:
            logger.error(f"Error analyzing intent: {str(e)}")
            return IntentAnalysis(
                intent=AgentIntent.UNKNOWN,
                confidence=0.0,
                extracted_parameters={},
                reasoning=f"Erro na anÃ¡lise: {str(e)}"
            )
    
    async def generate_response(
        self, 
        user_message: str, 
        sql_data: Optional[Dict[str, Any]], 
        conversation_history: List[ConversationMessage]
    ) -> str:
        """
        Gera uma resposta em linguagem natural baseada nos dados SQL.
        
        Args:
            user_message: Mensagem original do usuÃ¡rio
            sql_data: Dados retornados pela consulta SQL
            conversation_history: HistÃ³rico da conversa
            
        Returns:
            str: Resposta em linguagem natural
        """
        try:
            # Converter histÃ³rico para formato do LangChain
            messages = self._convert_history_to_messages(conversation_history)
            
            # Preparar dados SQL para o prompt
            sql_data_str = json.dumps(sql_data, indent=2, ensure_ascii=False) if sql_data else "Nenhum dado disponÃ­vel"
            
            # Executar geraÃ§Ã£o de resposta
            chain = self.response_prompt | self.llm
            
            result = await chain.ainvoke({
                "conversation_history": messages,
                "sql_data": sql_data_str,
                "user_message": user_message
            })
            
            return result.content
            
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            return f"Desculpe, ocorreu um erro ao processar sua solicitaÃ§Ã£o: {str(e)}"
    
    def _convert_history_to_messages(self, history: List[ConversationMessage]) -> List:
        """
        Converte histÃ³rico de conversa para formato do LangChain.
        
        Args:
            history: Lista de mensagens da conversa
            
        Returns:
            List: Mensagens no formato do LangChain
        """
        messages = []
        
        for msg in history:
            if msg.role == MessageRole.USER:
                messages.append(HumanMessage(content=msg.content))
            elif msg.role == MessageRole.ASSISTANT:
                messages.append(AIMessage(content=msg.content))
            elif msg.role == MessageRole.SYSTEM:
                messages.append(SystemMessage(content=msg.content))
        
        return messages
    
    async def process_message(self, payload: WebhookPayload) -> OrchestratorResponse:
        """
        Processa uma mensagem completa do usuÃ¡rio.
        
        Args:
            payload: Dados recebidos do webhook
            
        Returns:
            OrchestratorResponse: Resposta processada
        """
        try:
            logger.info(f"Processing message for session {payload.session_id}")
            
            # 1. Analisar intenÃ§Ã£o
            intent_analysis = await self.analyze_intent(payload)
            
            # 2. Processar baseado na intenÃ§Ã£o
            if intent_analysis.intent == AgentIntent.SQL_QUERY:
                # Importar aqui para evitar dependÃªncia circular
                from agents.sql_agent import SQLAgent
                
                sql_agent = SQLAgent()
                sql_response = await sql_agent.execute_query(
                    query_intent=payload.user_message,
                    parameters=intent_analysis.extracted_parameters,
                    session_id=payload.session_id
                )
                
                # Gerar resposta natural
                response_text = await self.generate_response(
                    user_message=payload.user_message,
                    sql_data=sql_response.data if sql_response.success else None,
                    conversation_history=payload.conversation_history
                )
                
            elif intent_analysis.intent == AgentIntent.GENERAL_CHAT:
                response_text = await self._handle_general_chat(payload)
                
            elif intent_analysis.intent == AgentIntent.HELP:
                response_text = self._get_help_response()
                
            else:
                response_text = "Desculpe, nÃ£o consegui entender sua solicitaÃ§Ã£o. Pode reformular a pergunta?"
            
            return OrchestratorResponse(
                response=response_text,
                session_id=payload.session_id,
                success=True,
                metadata={
                    "intent": intent_analysis.intent.value,
                    "confidence": intent_analysis.confidence
                }
            )
            
        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            return OrchestratorResponse(
                response=f"Ocorreu um erro interno. Tente novamente em alguns instantes.",
                session_id=payload.session_id,
                success=False,
                metadata={"error": str(e)}
            )
    
    async def _handle_general_chat(self, payload: WebhookPayload) -> str:
        """Lida com conversas gerais."""
        # ImplementaÃ§Ã£o simples para chat geral
        general_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="""
            VocÃª Ã© um assistente amigÃ¡vel que ajuda usuÃ¡rios com um sistema de consulta de dados.
            Responda de forma natural e educada. Se o usuÃ¡rio fizer perguntas sobre dados,
            sugira que ele faÃ§a uma pergunta especÃ­fica sobre os dados que deseja consultar.
            """),
            MessagesPlaceholder(variable_name="conversation_history"),
            HumanMessage(content="{user_message}")
        ])
        
        messages = self._convert_history_to_messages(payload.conversation_history)
        chain = general_prompt | self.llm
        
        result = await chain.ainvoke({
            "conversation_history": messages,
            "user_message": payload.user_message
        })
        
        return result.content
    
    def _get_help_response(self) -> str:
        """Retorna mensagem de ajuda."""
        return """
        OlÃ¡! Eu sou seu assistente para consultas de dados. Posso ajudÃ¡-lo com:
        
        ğŸ“Š **Consultas de dados**: FaÃ§a perguntas sobre seus dados, como:
        - "Quantos usuÃ¡rios temos cadastrados?"
        - "Mostre as vendas do Ãºltimo mÃªs"
        - "Qual produto mais vendido?"
        
        ğŸ’¬ **Conversa geral**: Posso responder perguntas sobre como usar o sistema
        
        ğŸ” **Dicas**: Seja especÃ­fico em suas perguntas para obter melhores resultados!
        
        Como posso ajudÃ¡-lo hoje?
        """
